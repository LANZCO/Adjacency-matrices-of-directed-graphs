{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27673123",
   "metadata": {},
   "source": [
    "Q1.1  Web2String 服务 \n",
    "安装requests、flask框架"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45dd1405",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\123\\lib\\site-packages (2.26.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\123\\lib\\site-packages (from requests) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\123\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\123\\lib\\site-packages (from requests) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\123\\lib\\site-packages (from requests) (1.26.7)\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3666fd0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flask in c:\\123\\lib\\site-packages (1.1.2)\n",
      "Requirement already satisfied: click>=5.1 in c:\\123\\lib\\site-packages (from flask) (8.0.3)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in c:\\123\\lib\\site-packages (from flask) (2.0.2)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in c:\\123\\lib\\site-packages (from flask) (2.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in c:\\123\\lib\\site-packages (from flask) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\123\\lib\\site-packages (from click>=5.1->flask) (0.4.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\123\\lib\\site-packages (from Jinja2>=2.10.1->flask) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b7674a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\123\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3452: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import requests as r\n",
    "from flask import Flask, request\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "def Web2string(url:str) -> str:\n",
    "    req = r.request('GET',url)\n",
    "    return req.text\n",
    "\n",
    "@app.route('/Web2string/', methods = ['GET','POST'])\n",
    "def welcome():\n",
    "    if request.method == 'POST':\n",
    "        url = requests.args.get('url')\n",
    "        return Web2string(url)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.debug = True\n",
    "    app.run(host = '0.0.0.0',port=2345)\n",
    "    \n",
    "def download_web_content(url:str) -> str:\n",
    "    req = r.request('GET',url)\n",
    "    return req.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "815819ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordfilter in c:\\123\\lib\\site-packages (0.2.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install wordfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0076098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: profanity-filter in c:\\123\\lib\\site-packages (1.3.3)\n",
      "Requirement already satisfied: ordered-set<4.0,>=3.0 in c:\\123\\lib\\site-packages (from profanity-filter) (3.1.1)\n",
      "Requirement already satisfied: redis<4.0,>=3.2 in c:\\123\\lib\\site-packages (from profanity-filter) (3.5.3)\n",
      "Requirement already satisfied: spacy<3.0,>=2.0 in c:\\123\\lib\\site-packages (from profanity-filter) (2.3.7)\n",
      "Requirement already satisfied: more-itertools<9.0,>=8.0 in c:\\123\\lib\\site-packages (from profanity-filter) (8.10.0)\n",
      "Requirement already satisfied: poetry-version<0.2.0,>=0.1.3 in c:\\123\\lib\\site-packages (from profanity-filter) (0.1.5)\n",
      "Requirement already satisfied: pydantic<2.0,>=1.3 in c:\\123\\lib\\site-packages (from profanity-filter) (1.9.0)\n",
      "Requirement already satisfied: ruamel.yaml<0.16.0,>=0.15.89 in c:\\123\\lib\\site-packages (from profanity-filter) (0.15.100)\n",
      "Requirement already satisfied: ordered-set-stubs<0.2.0,>=0.1.3 in c:\\123\\lib\\site-packages (from profanity-filter) (0.1.3)\n",
      "Requirement already satisfied: cached-property<2.0,>=1.5 in c:\\123\\lib\\site-packages (from profanity-filter) (1.5.2)\n",
      "Requirement already satisfied: tomlkit<0.6.0,>=0.4.6 in c:\\123\\lib\\site-packages (from poetry-version<0.2.0,>=0.1.3->profanity-filter) (0.5.11)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\123\\lib\\site-packages (from pydantic<2.0,>=1.3->profanity-filter) (3.10.0.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (4.62.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (1.0.6)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (1.0.5)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (1.20.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (0.9.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (2.26.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (0.7.7)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (1.0.0)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (7.4.5)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (1.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (58.0.4)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\123\\lib\\site-packages (from spacy<3.0,>=2.0->profanity-filter) (3.0.6)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\123\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0,>=2.0->profanity-filter) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\123\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0,>=2.0->profanity-filter) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\123\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0,>=2.0->profanity-filter) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\123\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.0,>=2.0->profanity-filter) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\123\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.0,>=2.0->profanity-filter) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install profanity-filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81c37f0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\123\\lib\\site-packages (2.3.7)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\123\\lib\\site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: thinc<7.5.0,>=7.4.1 in c:\\123\\lib\\site-packages (from spacy) (7.4.5)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in c:\\123\\lib\\site-packages (from spacy) (0.7.7)\n",
      "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in c:\\123\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\123\\lib\\site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\123\\lib\\site-packages (from spacy) (4.62.3)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\123\\lib\\site-packages (from spacy) (1.20.3)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in c:\\123\\lib\\site-packages (from spacy) (0.9.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\123\\lib\\site-packages (from spacy) (2.26.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\123\\lib\\site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: setuptools in c:\\123\\lib\\site-packages (from spacy) (58.0.4)\n",
      "Requirement already satisfied: plac<1.2.0,>=0.9.6 in c:\\123\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in c:\\123\\lib\\site-packages (from spacy) (1.0.0)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\123\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\123\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\123\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\123\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.7)\n",
      "Requirement already satisfied: colorama in c:\\123\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4fa9ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as r\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from typing import List, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9510745c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Patrick\n",
      "[nltk_data]     YIP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to C:\\Users\\Patrick\n",
      "[nltk_data]     YIP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5363783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def web2string(url: str) -> str:\n",
    "    reg = re.compile('<[^>]*>')\n",
    "    req = r.get(url).content\n",
    "    url = 'https://www.public.asu.edu/~ychen10/teaching/honors.html'\n",
    "    content = reg.sub('', req.decode(\"utf-8\")).replace('\\n', '').replace('\\r', ' ')\n",
    "    return content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d40c694",
   "metadata": {},
   "source": [
    "Q1.2  分析并筛选出功能词（停用词）\n",
    "首先定义停用词并且得出网页的内容，再进行分析和筛选停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec0bb6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_filter(words: str) -> list[Any]:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    word_tokens = word_tokenize(words)\n",
    "    filtered_sentence = ''\n",
    "    \n",
    "    for w in word_tokens:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence += ' ' + w\n",
    "    \n",
    "    return filtered_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9aba5afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"      Honors Resource Page for CSE492/493     Dr. Yinong Chen, Arizona State University     This pages shows a few resources that can help honors students to start defining their thesis topics and find faculty adviser who are in the thesis topic areas.                                    ASU Barrett Honors College                                                 Barrett Honors Faculty Advisers at Computer Science, Computer Systems Engineering, and Informatics                                                    CSE492 and CSE493 Honors Thesis Advising Page at SCAI.              A list of topics and SCAI faculty who offer Honor's theses                                                 Honors projects from other ASU schools                                                    Barret Faculty Honors Adviser Video Series: How do you choose your thesis project?                                                    All CSE Faculty Pages and Their Research Areas                                                    Sample CSE493 Honors Thesis Projects chaired by Dr. Yinong Chen                                                    Combine your Honors Thesis project with your CSE Capstone Project                                  Return to Dr. Chen's Home Page           \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_strings = web2string(\n",
    "    'https://www.public.asu.edu/~ychen10/teaching/honors.html')\n",
    "words_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce0fda15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" Honors Resource Page CSE492/493 Dr. Yinong Chen , Arizona State University This pages shows resources help honors students start defining thesis topics find faculty adviser thesis topic areas . ASU Barrett Honors College Barrett Honors Faculty Advisers Computer Science , Computer Systems Engineering , Informatics CSE492 CSE493 Honors Thesis Advising Page SCAI . A list topics SCAI faculty offer Honor 's theses Honors projects ASU schools Barret Faculty Honors Adviser Video Series : How choose thesis project ? All CSE Faculty Pages Their Research Areas Sample CSE493 Honors Thesis Projects chaired Dr. Yinong Chen Combine Honors Thesis project CSE Capstone Project Return Dr. Chen 's Home Page\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_filter(words_strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2d528b",
   "metadata": {},
   "source": [
    "Q1.3  Top10Words\n",
    "运用nltk的框架，分析前10个高频词汇"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b00022cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "allWords = nltk.tokenize.word_tokenize(words_strings)\n",
    "allWordDist = nltk.FreqDist(w.lower() for w in allWords)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "allWordExceptStopDist = nltk.FreqDist(w.lower() for w in allWords if w not in stopwords)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9622cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "mostCommon= allWordDist.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e17a8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('honors', 9), ('thesis', 6), ('and', 5), ('faculty', 5), ('page', 3), ('dr.', 3), ('chen', 3), (',', 3), ('your', 3), ('project', 3)]\n"
     ]
    }
   ],
   "source": [
    "print(mostCommon)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb555dc6",
   "metadata": {},
   "source": [
    "Q2.1  在此问题中，你将在 ASP .Net 框架中实现 Web 应用程序或在 Xamarin 框架中实现手机应 用程序。应用程序的架构如图 1 所示。你将实现图 1 中的所有部件。因为在问题 1 中已经 实现了前一半的部件，在问题 2 主要是实现后一半的问题，并调用在问题 1 中开发的的服务来构建应用程序。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7da83ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Restarting with watchdog (windowsapi)\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 1\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request, redirect, flash, url_for\n",
    "from Web2String import get_web_content, remove_tags, words_filter, top_ten_words, find_urls, tf_idf\n",
    "\n",
    "app = Flask(__name__)\n",
    "app.secret_key = 'amazing'\n",
    "\n",
    "@app.route('/')\n",
    "@app.route('/form')\n",
    "def form():\n",
    "    return render_template('form.html')\n",
    "\n",
    "\n",
    "@app.route('/answer', methods=['GET', 'POST'])\n",
    "def answer():\n",
    "    inputs = ''\n",
    "    for key, value in request.form.items():\n",
    "        if key == 'Input':\n",
    "            inputs = value\n",
    "\n",
    "    if not inputs:\n",
    "        flash(\"Input is required!\")\n",
    "        return redirect(url_for('form'))\n",
    "\n",
    "    content = get_web_content(inputs)\n",
    "\n",
    "    text = remove_tags(inputs)\n",
    "\n",
    "    filters = words_filter(text)\n",
    "\n",
    "    topten_doc1 = top_ten_words(filters, 1, 10)\n",
    "\n",
    "    topten_doc2, topten_doc3 = {}, {}\n",
    "\n",
    "    links = find_urls(inputs)\n",
    "    for i in range(len(links)):\n",
    "        contents = remove_tags(links[i])\n",
    "        filters = words_filter(contents)\n",
    "        my_dict = top_ten_words(filters, i+1, 10)\n",
    "        if i == 0:\n",
    "            topten_doc2 = my_dict\n",
    "        if i == 1:\n",
    "            topten_doc3 = my_dict\n",
    "\n",
    "    # TF-IDF\n",
    "    top_ten_words_tf_idf = tf_idf()\n",
    "\n",
    "    return render_template('form.html', content=content, filter=filters,\n",
    "                           topten_doc1=topten_doc1, topten_doc2=topten_doc2, topten_doc3=topten_doc3,\n",
    "                           top_ten_words_tf_idf=top_ten_words_tf_idf)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(host='0.0.0.0', port=2345, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53047a7",
   "metadata": {},
   "source": [
    "下载网页内容，并且移除网页标签，过滤停用词并且展示前十个高频词。分别保存3个文档，计算出TF-IDF值(idf = math.log2(3/value))。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37c989ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'words_1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\PATRIC~1\\AppData\\Local\\Temp/ipykernel_15736/1234362030.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mfile_name\u001b[0m \u001b[1;33m=\u001b[0m  \u001b[1;34mf'words_{abs(idx+1)}.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfile_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'words_1.txt'"
     ]
    }
   ],
   "source": [
    "@app.route('/tf-idf')\n",
    "def tf_idf() -> dict[str, float]:\n",
    "    new_dict = {}\n",
    "    res_dict = {}\n",
    "\n",
    "for idx in range(3):\n",
    "    file_name =  f'words_{abs(idx+1)}.txt'\n",
    "    f = open(file=file_name,mode='r',encoding='utf-8')\n",
    "    data = json.load(f)\n",
    "    \n",
    "    for key,value in data.items():\n",
    "        if new_dict.get(key):\n",
    "            new_dict[key] += 1\n",
    "        else:\n",
    "            new_dict[key] = 1\n",
    "\n",
    "    for key,value in new_data.items():\n",
    "        idf = math.log2(3/value)\n",
    "        print('idf value:',idf)\n",
    "        tf_idf = idf *value\n",
    "        res_dict[key] = tf_idf\n",
    "\n",
    "    res = sorted(res_dict.tems(),key=lambda kv:(kv[1],kv[0]), reverse = True)\n",
    "    \n",
    "    my_dict = dict((x,y) for x,y in res[:10])\n",
    "    \n",
    "my_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc83dfa2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
